{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Sequential\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.layers import LSTM,Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '/Users/M NILESH/Downloads/Label10000.csv'\n",
    "df=pd.read_csv(input_file)[['text','label']]\n",
    "df['word_count']=df['text'].apply(lambda x: len(str(x).split(\" \")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------> 0\n"
     ]
    }
   ],
   "source": [
    "common_words=pd.Series(''.join(df['text']).split()).value_counts()\n",
    "texts=[]\n",
    "labels=[]\n",
    "for i in range(len(df)):\n",
    "    if i%10000==0:\n",
    "        print(\"------>\",i)\n",
    "    words=word_tokenize(df.loc[i].text)\n",
    "    final_words=[]\n",
    "    for word in words:\n",
    "        if not (word in common_words[:3] or word in common_words[-1000:]):\n",
    "            final_words.append(word)\n",
    "    words = final_words\n",
    "    extracted_sentence=' '.join(word for word in words)\n",
    "    texts.append(extracted_sentence)\n",
    "    labels.append(df.loc[i]['label'])\n",
    "new_df=pd.DataFrame({\n",
    "    'text':texts,\n",
    "    'label':labels\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_text=[]\n",
    "news_label=[]\n",
    "for n_z in new_df['text']:\n",
    "  tokenize_text.append(n_z)\n",
    "for l in new_df['label']:\n",
    "  news_label.append(l)\n",
    "x_tk = Tokenizer()\n",
    "x_tk.fit_on_texts(tokenize_text)\n",
    "text_tokenized, text_tokenizer=x_tk.texts_to_sequences(tokenize_text), x_tk\n",
    "length = None\n",
    "if length is None:\n",
    "    length = len(max(text_tokenized, key=len))\n",
    "text_padded=pad_sequences(text_tokenized, maxlen=length, padding='post')\n",
    "trainX=text_padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = pd.get_dummies(news_label).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainX, trainY, test_size=0.2, random_state=56)\n",
    "trainX = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "testX = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "newtest=[]\n",
    "refined_out = testX.astype(np.float)\n",
    "for i in refined_out:\n",
    "    for j in i:\n",
    "        newtest.append(j)\n",
    "refined_data = trainX.astype(np.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/30\n",
      " - 13s - loss: 0.5827 - accuracy: 0.6903 - val_loss: 0.5415 - val_accuracy: 0.7225\n",
      "Epoch 2/30\n",
      " - 4s - loss: 0.5020 - accuracy: 0.7511 - val_loss: 0.5192 - val_accuracy: 0.7369\n",
      "Epoch 3/30\n",
      " - 4s - loss: 0.4764 - accuracy: 0.7678 - val_loss: 0.5036 - val_accuracy: 0.7444\n",
      "Epoch 4/30\n",
      " - 4s - loss: 0.4603 - accuracy: 0.7786 - val_loss: 0.4772 - val_accuracy: 0.7613\n",
      "Epoch 5/30\n",
      " - 4s - loss: 0.4460 - accuracy: 0.7836 - val_loss: 0.4632 - val_accuracy: 0.7750\n",
      "Epoch 6/30\n",
      " - 4s - loss: 0.4325 - accuracy: 0.7887 - val_loss: 0.4616 - val_accuracy: 0.7800\n",
      "Epoch 7/30\n",
      " - 4s - loss: 0.4302 - accuracy: 0.7934 - val_loss: 0.4520 - val_accuracy: 0.7825\n",
      "Epoch 8/30\n",
      " - 4s - loss: 0.4216 - accuracy: 0.8047 - val_loss: 0.4419 - val_accuracy: 0.7906\n",
      "Epoch 9/30\n",
      " - 4s - loss: 0.4116 - accuracy: 0.8045 - val_loss: 0.4334 - val_accuracy: 0.7931\n",
      "Epoch 10/30\n",
      " - 4s - loss: 0.4038 - accuracy: 0.8134 - val_loss: 0.4263 - val_accuracy: 0.7931\n",
      "Epoch 11/30\n",
      " - 3s - loss: 0.4023 - accuracy: 0.8119 - val_loss: 0.4289 - val_accuracy: 0.7925\n",
      "Epoch 12/30\n",
      " - 3s - loss: 0.3978 - accuracy: 0.8119 - val_loss: 0.4181 - val_accuracy: 0.7981\n",
      "Epoch 13/30\n",
      " - 3s - loss: 0.3946 - accuracy: 0.8164 - val_loss: 0.4187 - val_accuracy: 0.7987\n",
      "Epoch 14/30\n",
      " - 3s - loss: 0.3931 - accuracy: 0.8166 - val_loss: 0.4125 - val_accuracy: 0.8037\n",
      "Epoch 15/30\n",
      " - 3s - loss: 0.3864 - accuracy: 0.8225 - val_loss: 0.4068 - val_accuracy: 0.8050\n",
      "Epoch 16/30\n",
      " - 3s - loss: 0.3870 - accuracy: 0.8236 - val_loss: 0.4074 - val_accuracy: 0.8050\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.3870 - accuracy: 0.8220 - val_loss: 0.4016 - val_accuracy: 0.8069\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.3781 - accuracy: 0.8220 - val_loss: 0.3924 - val_accuracy: 0.8106\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.3763 - accuracy: 0.8319 - val_loss: 0.3914 - val_accuracy: 0.8169\n",
      "Epoch 20/30\n",
      " - 3s - loss: 0.3760 - accuracy: 0.8292 - val_loss: 0.3975 - val_accuracy: 0.8106\n",
      "Epoch 21/30\n",
      " - 3s - loss: 0.3686 - accuracy: 0.8341 - val_loss: 0.3935 - val_accuracy: 0.8163\n",
      "Epoch 22/30\n",
      " - 3s - loss: 0.3625 - accuracy: 0.8364 - val_loss: 0.3871 - val_accuracy: 0.8194\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.3651 - accuracy: 0.8377 - val_loss: 0.3851 - val_accuracy: 0.8150\n",
      "Epoch 24/30\n",
      " - 3s - loss: 0.3543 - accuracy: 0.8386 - val_loss: 0.3778 - val_accuracy: 0.8219\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.3588 - accuracy: 0.8434 - val_loss: 0.3774 - val_accuracy: 0.8263\n",
      "Epoch 26/30\n",
      " - 3s - loss: 0.3616 - accuracy: 0.8417 - val_loss: 0.3804 - val_accuracy: 0.8300\n",
      "Epoch 27/30\n",
      " - 3s - loss: 0.3550 - accuracy: 0.8473 - val_loss: 0.3732 - val_accuracy: 0.8344\n",
      "Epoch 28/30\n",
      " - 3s - loss: 0.3512 - accuracy: 0.8483 - val_loss: 0.3698 - val_accuracy: 0.8369\n",
      "Epoch 29/30\n",
      " - 3s - loss: 0.3520 - accuracy: 0.8466 - val_loss: 0.3736 - val_accuracy: 0.8338\n",
      "Epoch 30/30\n",
      " - 3s - loss: 0.3544 - accuracy: 0.8472 - val_loss: 0.3726 - val_accuracy: 0.8394\n"
     ]
    }
   ],
   "source": [
    "opt=SGD(lr=0.001)\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(128,input_shape=(1,X_train.shape[1]),dropout=0.2)))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model.fit(refined_data, y_train, epochs=30, batch_size=32, verbose=2,validation_split=0.2)\n",
    "model.save(\"Bidirectional.h5\")\n",
    "output=model.predict(refined_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "newout=[]\n",
    "for i in range(len(output)):\n",
    "    if output[i][1]>0.5:\n",
    "        newout.append(1)\n",
    "    else:\n",
    "        newout.append(0)\n",
    "count1=0\n",
    "for i in range(len(newout)):\n",
    "    if newout[i]==y_test[i][1]:\n",
    "        count1+=1\n",
    "if (count1>len(newout)-count1):\n",
    "    print('1')\n",
    "else:\n",
    "    print('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/30\n",
      " - 3s - loss: 0.5367 - accuracy: 0.7406 - val_loss: 0.5273 - val_accuracy: 0.7400\n",
      "Epoch 2/30\n",
      " - 2s - loss: 0.4919 - accuracy: 0.7666 - val_loss: 0.5097 - val_accuracy: 0.7481\n",
      "Epoch 3/30\n",
      " - 2s - loss: 0.4687 - accuracy: 0.7833 - val_loss: 0.4818 - val_accuracy: 0.7675\n",
      "Epoch 4/30\n",
      " - 2s - loss: 0.4528 - accuracy: 0.7886 - val_loss: 0.4661 - val_accuracy: 0.7631\n",
      "Epoch 5/30\n",
      " - 2s - loss: 0.4454 - accuracy: 0.7947 - val_loss: 0.4624 - val_accuracy: 0.7794\n",
      "Epoch 6/30\n",
      " - 2s - loss: 0.4465 - accuracy: 0.7923 - val_loss: 0.4652 - val_accuracy: 0.7800\n",
      "Epoch 7/30\n",
      " - 2s - loss: 0.4343 - accuracy: 0.8059 - val_loss: 0.4526 - val_accuracy: 0.7831\n",
      "Epoch 8/30\n",
      " - 2s - loss: 0.4319 - accuracy: 0.8020 - val_loss: 0.4331 - val_accuracy: 0.7981\n",
      "Epoch 9/30\n",
      " - 2s - loss: 0.4177 - accuracy: 0.8062 - val_loss: 0.4392 - val_accuracy: 0.7875\n",
      "Epoch 10/30\n",
      " - 2s - loss: 0.4188 - accuracy: 0.8055 - val_loss: 0.4350 - val_accuracy: 0.7894\n",
      "Epoch 11/30\n",
      " - 2s - loss: 0.4139 - accuracy: 0.8102 - val_loss: 0.4326 - val_accuracy: 0.8062\n",
      "Epoch 12/30\n",
      " - 2s - loss: 0.4143 - accuracy: 0.8136 - val_loss: 0.4271 - val_accuracy: 0.8037\n",
      "Epoch 13/30\n",
      " - 2s - loss: 0.4072 - accuracy: 0.8158 - val_loss: 0.4227 - val_accuracy: 0.7975\n",
      "Epoch 14/30\n",
      " - 2s - loss: 0.4029 - accuracy: 0.8219 - val_loss: 0.4309 - val_accuracy: 0.7956\n",
      "Epoch 15/30\n",
      " - 2s - loss: 0.4069 - accuracy: 0.8178 - val_loss: 0.4233 - val_accuracy: 0.8006\n",
      "Epoch 16/30\n",
      " - 2s - loss: 0.3987 - accuracy: 0.8238 - val_loss: 0.4172 - val_accuracy: 0.7981\n",
      "Epoch 17/30\n",
      " - 2s - loss: 0.3930 - accuracy: 0.8233 - val_loss: 0.4150 - val_accuracy: 0.8012\n",
      "Epoch 18/30\n",
      " - 2s - loss: 0.3956 - accuracy: 0.8214 - val_loss: 0.4052 - val_accuracy: 0.8025\n",
      "Epoch 19/30\n",
      " - 2s - loss: 0.3866 - accuracy: 0.8261 - val_loss: 0.4034 - val_accuracy: 0.8025\n",
      "Epoch 20/30\n",
      " - 2s - loss: 0.3892 - accuracy: 0.8238 - val_loss: 0.4025 - val_accuracy: 0.8100\n",
      "Epoch 21/30\n",
      " - 2s - loss: 0.3830 - accuracy: 0.8295 - val_loss: 0.3967 - val_accuracy: 0.8100\n",
      "Epoch 22/30\n",
      " - 2s - loss: 0.3779 - accuracy: 0.8297 - val_loss: 0.3985 - val_accuracy: 0.8194\n",
      "Epoch 23/30\n",
      " - 2s - loss: 0.3851 - accuracy: 0.8250 - val_loss: 0.3953 - val_accuracy: 0.8156\n",
      "Epoch 24/30\n",
      " - 2s - loss: 0.3738 - accuracy: 0.8306 - val_loss: 0.3889 - val_accuracy: 0.8206\n",
      "Epoch 25/30\n",
      " - 2s - loss: 0.3790 - accuracy: 0.8277 - val_loss: 0.3846 - val_accuracy: 0.8194\n",
      "Epoch 26/30\n",
      " - 2s - loss: 0.3765 - accuracy: 0.8269 - val_loss: 0.3824 - val_accuracy: 0.8269\n",
      "Epoch 27/30\n",
      " - 2s - loss: 0.3733 - accuracy: 0.8313 - val_loss: 0.3901 - val_accuracy: 0.8206\n",
      "Epoch 28/30\n",
      " - 2s - loss: 0.3680 - accuracy: 0.8339 - val_loss: 0.3843 - val_accuracy: 0.8169\n",
      "Epoch 29/30\n",
      " - 2s - loss: 0.3705 - accuracy: 0.8355 - val_loss: 0.3792 - val_accuracy: 0.8219\n",
      "Epoch 30/30\n",
      " - 2s - loss: 0.3627 - accuracy: 0.8359 - val_loss: 0.3812 - val_accuracy: 0.8194\n"
     ]
    }
   ],
   "source": [
    "opt=SGD(lr=0.001)\n",
    "model = Sequential()\n",
    "model.add(LSTM(128,input_shape=(1,X_train.shape[1]),dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\n",
    "model.fit(refined_data, y_train, epochs=30, batch_size=32, verbose=2,validation_split=0.2)\n",
    "model.save(\"lstm.h5\")\n",
    "output=model.predict(refined_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "newout=[]\n",
    "for i in range(len(output)):\n",
    "    if output[i][1]>0.5:\n",
    "        newout.append(1)\n",
    "    else:\n",
    "        newout.append(0)\n",
    "count1=0\n",
    "for i in range(len(newout)):\n",
    "    if newout[i]==y_test[i][1]:\n",
    "        count1+=1\n",
    "if (count1>len(newout)-count1):\n",
    "    print('1')\n",
    "else:\n",
    "    print('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('ProgramData': virtualenv)",
   "language": "python",
   "name": "python37464bitprogramdatavirtualenv7ca05a9d93bd447290dedaaeb26bf1fb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
