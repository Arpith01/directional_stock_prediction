{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVC_API.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arpith01/directional_stock_prediction/blob/master/notebooks/models/SVC_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GLjPuAR4fji"
      },
      "source": [
        "!pip install colabcode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcvF3aVK4jg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f14b323a-19f5-42af-8d09-5498a770ca9e"
      },
      "source": [
        "!pip install fastapi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastapi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/33/1b643f650688ad368983bbaf3b0658438038ea84d775dd37393d826c3833/fastapi-0.63.0-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.6MB/s \n",
            "\u001b[?25hCollecting pydantic<2.0.0,>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/a3/0ffdb6c63f45f10d19b8e8b32670b22ed089cafb29732f6bf8ce518821fb/pydantic-1.8.1-cp37-cp37m-manylinux2014_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 19.0MB/s \n",
            "\u001b[?25hCollecting starlette==0.13.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/a4/c9e228d7d47044ce4c83ba002f28ff479e542455f0499198a3f77c94f564/starlette-0.13.6-py3-none-any.whl (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic<2.0.0,>=1.0.0->fastapi) (3.7.4.3)\n",
            "Installing collected packages: pydantic, starlette, fastapi\n",
            "Successfully installed fastapi-0.63.0 pydantic-1.8.1 starlette-0.13.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RPU3_n24pK3"
      },
      "source": [
        "import unicodedata\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.downloader.download('vader_lexicon')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import LancasterStemmer,PorterStemmer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "from nltk.stem import LancasterStemmer,PorterStemmer\n",
        "\n",
        "\n",
        "def nonAsciiChar(words):\n",
        "    words_list=[]\n",
        "    for w in words:\n",
        "        w=re.sub('[^a-zA-Z]+','',re.sub(r'[\\W\\d]','',w.lower()))\n",
        "        format_words=unicodedata.normalize('NFKD', w).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        words_list.append(format_words)\n",
        "        \n",
        "    return words_list\n",
        "def stemWordsRemoval(words):\n",
        "    stemmer = PorterStemmer()\n",
        "    words_list=[]\n",
        "    for word in words:\n",
        "        word=stemmer.stem(word)\n",
        "        if word not in words_list:\n",
        "            words_list.append(word)\n",
        "    return words_list\n",
        "\n",
        "def stopWordsRemoval(words):\n",
        "    words_list=[]\n",
        "    for w in words:\n",
        "        if w not in stopwords:\n",
        "            words_list.append(w)\n",
        "    return words_list\n",
        "\n",
        "def removeLinks(words):\n",
        "    words_list=[]\n",
        "    for w in words:\n",
        "        if not re.match('[www]',w):\n",
        "            words_list.append(w)\n",
        "    return words_list\n",
        "\n",
        "def spaceRemoval(words):\n",
        "    words_list=[]\n",
        "    for w in words:\n",
        "        if w!='':\n",
        "            words_list.append(w)\n",
        "    return words_list\n",
        "\n",
        "\n",
        "def dataExtraction(words):\n",
        "    words=nonAsciiChar(words)\n",
        "    words=spaceRemoval(words)\n",
        "    words=stopWordsRemoval(words)\n",
        "    words=stemWordsRemoval(words)\n",
        "    words=removeLinks(words)\n",
        "    return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opwDmjVQ4yZc"
      },
      "source": [
        "def get_sentences(news_article):\n",
        "    paragraphs = nltk.sent_tokenize(news_article.lower())\n",
        "    sentences=[]\n",
        "    is_amazon = []\n",
        "    amzn_sentences = []\n",
        "    apple_sentences = []\n",
        "    key_words=['amazon','apple','aapl','amzn']\n",
        "    amazon_keywords = ['amazon', 'amzn']\n",
        "    apple_keywords = ['apple', 'aapl']\n",
        "\n",
        "    for para in paragraphs:\n",
        "      sentences_list = para.split(\"\\n\")\n",
        "      for sentence in sentences_list:\n",
        "        if any(key in sentence for key in amazon_keywords):\n",
        "          sentences.append(sentence)\n",
        "          is_amazon.append(1)\n",
        "        if any(key in sentence for key in apple_keywords):\n",
        "          sentences.append(sentence)\n",
        "          is_amazon.append(0)\n",
        "          # if any(key in sentence for key in key_words):\n",
        "          #   sentences.append(sentence)\n",
        "\n",
        "\n",
        "    if len(sentences) == 0:\n",
        "      return None\n",
        "    \n",
        "    sentences_df = pd.DataFrame({'text':sentences, 'is_amazon':is_amazon})\n",
        "\n",
        "    sentences_df=sentences_df[sentences_df['text'].str.match('^[A-Z a-z 0-9]+')]\n",
        "\n",
        "    sentences_df=sentences_df.drop_duplicates(keep=False).reset_index(drop=True)\n",
        "\n",
        "    sentences_df['words'] = sentences_df.text.apply(word_tokenize)\n",
        "    sentences_df['words'] = sentences_df.words.apply(dataExtraction)\n",
        "    sentences_df['text'] = sentences_df.words.apply(lambda words: \" \".join(words))\n",
        "    sentences_df = sentences_df.drop(columns=\"words\")\n",
        "\n",
        "    return sentences_df"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfTZUVKe47HO"
      },
      "source": [
        "from pydantic import BaseModel\n",
        "from fastapi import FastAPI"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27ozejKW495A"
      },
      "source": [
        "from fastapi.middleware.cors import CORSMiddleware"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7r_rD8t5Aav"
      },
      "source": [
        "class Sentence(BaseModel):\n",
        "  news_article:str"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7UY81Zp5CY6"
      },
      "source": [
        "class Prediction(BaseModel):\n",
        "  prediction_apple:str\n",
        "  confidence_apple:str\n",
        "  prediction_amazon:str\n",
        "  confidence_amazon:str"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiVwdgpb5EG5"
      },
      "source": [
        "app = FastAPI()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf5379tT5HgQ"
      },
      "source": [
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWKMuHGf825b",
        "outputId": "05e0d737-e6cb-4002-b302-b8f22791f59c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVJ0s3R780iE",
        "outputId": "502b882e-cc25-4633-e13f-5ef3d5415de6"
      },
      "source": [
        "import pickle\n",
        "path = \"/content/drive/MyDrive/new_data_ARS/SVM_LinearSVC_2.sav\"\n",
        "infile = open(path,'rb')\n",
        "SVC_Linear = pickle.load(infile)\n",
        "infile.close()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearSVC from version 0.23.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inCiVPcV5RKi",
        "outputId": "0ba61f58-9e2c-46f1-807a-44b5253d69b4"
      },
      "source": [
        "saved_model = SVC_Linear\n",
        "saved_model"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blxNHPhBJZC3"
      },
      "source": [
        "path = \"/content/drive/MyDrive/new_data_ARS/vectorizer\"\n",
        "infile = open(path,'rb')\n",
        "vectorizer_dict = pickle.load(infile)\n",
        "infile.close()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhqy-CpOKjtX"
      },
      "source": [
        "vectorizer = vectorizer_dict['vectorizer']"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3rf5W7gKuUq",
        "outputId": "be35b10c-d327-4784-946f-cfe837c2f9c0"
      },
      "source": [
        "vectorizer"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=4000, min_df=10,\n",
              "                ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4OnyV2KCEdT"
      },
      "source": [
        "def get_features(X_test):\n",
        "  cls = SentimentIntensityAnalyzer()\n",
        "  Positive_X_test_text = []\n",
        "  Negative_X_test_text = []\n",
        "\n",
        "  for i in tqdm(X_test):\n",
        "      n1= cls.polarity_scores(i)[\"neg\"]\n",
        "      n2= cls.polarity_scores(i)[\"pos\"]\n",
        "      Positive_X_test_text.append(n1)\n",
        "      Negative_X_test_text.append(n2)\n",
        "  \n",
        "  # vectorizer = CountVectorizer(ngram_range = (2,2),max_features = 4000, min_df = 10)\n",
        "  \n",
        "  X_test_2gram_features = vectorizer.transform(X_test)\n",
        "  Sentiment_X_test_text = np.column_stack((Positive_X_test_text, Negative_X_test_text))\n",
        "\n",
        "  X_test_2gram_features_array = X_test_2gram_features.toarray()\n",
        "  Xtest = np.concatenate((Sentiment_X_test_text,X_test_2gram_features_array), axis = 1)\n",
        "  return Xtest"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaaLKe-55Jb9"
      },
      "source": [
        "@app.on_event(\"startup\")\n",
        "def load_model_from_file():\n",
        "  global inference_model\n",
        "  inference_model = saved_model\n",
        "\n",
        "\n",
        "@app.get('/')\n",
        "def index():\n",
        "  return{'message':'Post an article to this API to get inference'}\n",
        "\n",
        "@app.post('/predict')\n",
        "def classify_sentence(data:Sentence):\n",
        "  received_data = data.dict()\n",
        "  news_article = received_data['news_article']\n",
        "  sentences = get_sentences(news_article)\n",
        "  prediction_class_amzn = \"-1\"\n",
        "  prediction_class_apple = \"-1\"\n",
        "  confidence_amzn = '0'\n",
        "  confidence_apple = '0'\n",
        "\n",
        "  if sentences is None:\n",
        "    p = Prediction(prediction_apple=prediction_class_apple, confidence_apple=confidence_apple, prediction_amazon = prediction_class_amzn, confidence_amazon=confidence_amzn)\n",
        "    return p\n",
        "\n",
        "\n",
        "  amazon_sentences = sentences[sentences['is_amazon'] == 1].text\n",
        "  apple_sentences = sentences[sentences['is_amazon'] == 0].text\n",
        "\n",
        "  # posterior_prob = tf.sigmoid(inference_model.predict(sentences))\n",
        "\n",
        "  if(len(amazon_sentences) != 0):\n",
        "    amazon_sentences_test = get_features(amazon_sentences)\n",
        "    posterior_prob_amzn = inference_model.predict(amazon_sentences_test)\n",
        "    prediction_class_amzn = np.where(posterior_prob_amzn>0.5, 1, 0)\n",
        "    bin_count_amzn = np.bincount(prediction_class_amzn.flatten())\n",
        "\n",
        "    prediction_class_amzn = np.bincount(prediction_class_amzn.flatten()).argmax()\n",
        "\n",
        "    confidence_amzn = bin_count_amzn[prediction_class_amzn]/np.sum(bin_count_amzn)\n",
        "    confidence_amzn = str(confidence_amzn)\n",
        "    prediction_class_amzn = str(prediction_class_amzn)\n",
        "\n",
        "\n",
        "  if(len(apple_sentences) != 0):\n",
        "    apple_sentences_test = get_features(apple_sentences)\n",
        "    posterior_prob_apple = inference_model.predict(apple_sentences_test)\n",
        "    prediction_class_apple = np.where(posterior_prob_apple>0.5, 1, 0)\n",
        "    bin_count_apple = np.bincount(prediction_class_apple.flatten())\n",
        "\n",
        "    prediction_class_apple = np.bincount(prediction_class_apple.flatten()).argmax()\n",
        "\n",
        "    confidence_apple = bin_count_apple[prediction_class_apple]/np.sum(bin_count_apple)\n",
        "    prediction_class_apple = str(prediction_class_apple)\n",
        "    confidence_apple = str(confidence_apple)\n",
        "\n",
        "  # prediction_classes = np.where(posterior_prob>0.5, 1, 0)\n",
        "\n",
        "  # print(prediction_classes)\n",
        "  # prediction_class = np.bincount(prediction_classes.flatten()).argmax()\n",
        "  # p = Prediction(prediction=str(prediction_class))\n",
        "  p = Prediction(prediction_apple=prediction_class_apple, confidence_apple=confidence_apple, prediction_amazon = prediction_class_amzn, confidence_amazon=confidence_amzn)\n",
        "\n",
        "  return p"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0--COygJnROC"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "amazon_full = pd.read_csv(\"/content/drive/MyDrive/Amazon_csvs_published_source/Label46623.csv\")\n",
        "\n",
        "apple_full = pd.read_csv(\"/content/drive/MyDrive/apple_csvs_published_source/Label30000.csv\")\n",
        "\n",
        "amazon_full = amazon_full[amazon_full.text.notnull()]\n",
        "apple_full = apple_full[apple_full.text.notnull()]\n",
        "\n",
        "amazon_test = amazon_full.sample(frac=0.5, random_state=42).reset_index(drop=True)\n",
        "apple_test = apple_full.sample(frac=0.5, random_state=42).reset_index(drop=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bM2aNFUCwAaR"
      },
      "source": [
        "def get_counts(test):\n",
        "  # print(apple_test)\n",
        "  predictions = saved_model.predict(get_features(test[:5000].text))\n",
        "  # sig_preds = tf.sigmoid(predictions)\n",
        "  sig_preds = np.where(predictions>=0.5, 1, 0)\n",
        "\n",
        "  print(classification_report(test[:5000].label, sig_preds))\n",
        "  print(confusion_matrix(test[:5000].label, sig_preds))\n",
        "\n",
        "  a_df = pd.DataFrame({\"sites\":test[:5000][sig_preds.flatten() == test[:5000].label].source})\n",
        "  print(a_df.sites.value_counts())\n",
        "  print(test[:5000].source.value_counts())"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeE8n6q5v_xu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "455f08cc-7945-4bce-ed76-75f757f59492"
      },
      "source": [
        "get_counts(apple_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5000/5000 [00:02<00:00, 2295.56it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.66      0.63      3007\n",
            "           1       0.42      0.37      0.39      1993\n",
            "\n",
            "    accuracy                           0.54      5000\n",
            "   macro avg       0.51      0.51      0.51      5000\n",
            "weighted avg       0.53      0.54      0.54      5000\n",
            "\n",
            "[[1970 1037]\n",
            " [1254  739]]\n",
            "www.yahoo.com             1980\n",
            "seekingalpha.com           371\n",
            "news.morningstar.com       165\n",
            "investingnews.com           95\n",
            "www.businesswire.com        82\n",
            "www.thestreet.com           11\n",
            "freeamericanetwork.com       3\n",
            "www.investors.com            1\n",
            "www.fool.com                 1\n",
            "Name: sites, dtype: int64\n",
            "www.yahoo.com             3124\n",
            "seekingalpha.com          1033\n",
            "www.businesswire.com       332\n",
            "investingnews.com          256\n",
            "news.morningstar.com       225\n",
            "www.thestreet.com           20\n",
            "www.investors.com            4\n",
            "freeamericanetwork.com       4\n",
            "seoland.in                   1\n",
            "www.fool.com                 1\n",
            "Name: source, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75wjBdE7v_Eo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "265a7843-75d6-4eee-81ac-6a17de44b78e"
      },
      "source": [
        "get_counts(apple_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5000/5000 [00:02<00:00, 2286.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.66      0.63      3007\n",
            "           1       0.42      0.37      0.39      1993\n",
            "\n",
            "    accuracy                           0.54      5000\n",
            "   macro avg       0.51      0.51      0.51      5000\n",
            "weighted avg       0.53      0.54      0.54      5000\n",
            "\n",
            "[[1970 1037]\n",
            " [1254  739]]\n",
            "www.yahoo.com             1980\n",
            "seekingalpha.com           371\n",
            "news.morningstar.com       165\n",
            "investingnews.com           95\n",
            "www.businesswire.com        82\n",
            "www.thestreet.com           11\n",
            "freeamericanetwork.com       3\n",
            "www.investors.com            1\n",
            "www.fool.com                 1\n",
            "Name: sites, dtype: int64\n",
            "www.yahoo.com             3124\n",
            "seekingalpha.com          1033\n",
            "www.businesswire.com       332\n",
            "investingnews.com          256\n",
            "news.morningstar.com       225\n",
            "www.thestreet.com           20\n",
            "www.investors.com            4\n",
            "freeamericanetwork.com       4\n",
            "seoland.in                   1\n",
            "www.fool.com                 1\n",
            "Name: source, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEQH_hzMD4cZ",
        "outputId": "b4975a2c-71fe-4620-b0b3-4d79c825b4e5"
      },
      "source": [
        "import json\n",
        "\n",
        "amazon_full = pd.read_csv(\"/content/drive/MyDrive/Amazon_csvs_published_source/Label46623.csv\")\n",
        "apple_full = pd.read_csv(\"/content/drive/MyDrive/apple_csvs_published_source/Label30000.csv\")\n",
        "\n",
        "amazon_full = amazon_full[amazon_full.text.notnull()]\n",
        "apple_full = apple_full[apple_full.text.notnull()]\n",
        "\n",
        "amazon_test = amazon_full.sample(frac=0.5, random_state=42).reset_index(drop=True)\n",
        "apple_test = apple_full.sample(frac=0.5, random_state=42).reset_index(drop=True)\n",
        "\n",
        "test_data = pd.concat([apple_test, amazon_test])\n",
        "test_data = test_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "### Run your testing logic here (generate features...)\n",
        "predictions = saved_model.predict(get_features(test_data.text))\n",
        "# sig_preds = tf.sigmoid(predictions)\n",
        "sig_preds = np.where(predictions>=0.5, 1, 0)\n",
        "\n",
        "print(classification_report(test_data.label, sig_preds))\n",
        "print(confusion_matrix(test_data.label, sig_preds))\n",
        "\n",
        "results_df = pd.DataFrame({\"site\":test_data.source, \"ground_truth\":test_data.label, \"predicted\":sig_preds.flatten()})\n",
        "### Check until here\n",
        "\n",
        "results_df[\"correct\"] = np.where(results_df.ground_truth == results_df.predicted, 1, 0)\n",
        "results_df = results_df.drop(columns=['ground_truth', 'predicted'])\n",
        "\n",
        "site_stats = results_df.groupby([\"site\"]).agg(['count', 'sum'])\n",
        "site_stats.columns = ['_'.join(col) for col in site_stats.columns.values]\n",
        "site_stats.reset_index(inplace=True)\n",
        "site_stats.rename(columns={\"correct_count\":\"support\",\"correct_sum\":\"correct\"}, inplace=True)\n",
        "site_stats[\"accuracy\"] = 100 * site_stats.correct/site_stats.support\n",
        "\n",
        "site_stats_50 = site_stats[site_stats.support > 50]\n",
        "\n",
        "top_10_sites = site_stats_50.sort_values(by=['accuracy'], ascending=False).iloc[:10]\n",
        "\n",
        "for index, row in top_10_sites.iterrows():\n",
        "  d = {\"site\":str(row.site), \"accuracy\":str(row.accuracy), \"support\":str(row.support)}\n",
        "  print(json.dumps(d)+\",\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 38312/38312 [00:24<00:00, 1573.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.74      0.72     25859\n",
            "           1       0.40      0.35      0.38     12453\n",
            "\n",
            "    accuracy                           0.62     38312\n",
            "   macro avg       0.55      0.55      0.55     38312\n",
            "weighted avg       0.61      0.62      0.61     38312\n",
            "\n",
            "[[19253  6606]\n",
            " [ 8049  4404]]\n",
            "{\"site\": \"www.yahoo.com\", \"accuracy\": \"74.74617711657204\", \"support\": \"24131\"},\n",
            "{\"site\": \"news.morningstar.com\", \"accuracy\": \"66.62576687116564\", \"support\": \"815\"},\n",
            "{\"site\": \"finance.yahoo.com\", \"accuracy\": \"60.317460317460316\", \"support\": \"63\"},\n",
            "{\"site\": \"www.financialnewsusa.com\", \"accuracy\": \"51.92307692307692\", \"support\": \"52\"},\n",
            "{\"site\": \"googlejuices.com\", \"accuracy\": \"48.81516587677725\", \"support\": \"211\"},\n",
            "{\"site\": \"www.investors.com\", \"accuracy\": \"46.08391608391609\", \"support\": \"4290\"},\n",
            "{\"site\": \"www.topstocksforum.com\", \"accuracy\": \"37.93103448275862\", \"support\": \"58\"},\n",
            "{\"site\": \"investingnews.com\", \"accuracy\": \"35.25872442839952\", \"support\": \"831\"},\n",
            "{\"site\": \"seekingalpha.com\", \"accuracy\": \"33.99153737658674\", \"support\": \"5672\"},\n",
            "{\"site\": \"www.thestreet.com\", \"accuracy\": \"28.16377171215881\", \"support\": \"806\"},\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL4JJc6G6TEW"
      },
      "source": [
        "from colabcode import ColabCode\n",
        "server = ColabCode(port=10000, code=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-l1qYBq6T3g",
        "outputId": "4525b027-905d-4679-ad56-d2d54fb7e618"
      },
      "source": [
        "server.run_app(app)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [63]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:10000 (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Public URL: NgrokTunnel: \"http://fc8ffcd2c751.ngrok.io\" -> \"http://localhost:10000\"\n",
            "INFO:     72.223.1.23:0 - \"GET / HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 969.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     72.223.1.23:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 2/2 [00:00<00:00, 295.58it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 245.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     72.223.1.23:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 674.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     72.223.1.23:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 11/11 [00:00<00:00, 2309.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     72.223.1.23:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 11/11 [00:00<00:00, 1813.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     72.223.1.23:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 579.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     72.223.1.23:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 817.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     72.223.1.23:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     72.223.1.23:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 419.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     72.223.1.23:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 11/11 [00:00<00:00, 2005.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     72.223.1.23:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 620.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     72.223.1.23:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 609.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     72.223.1.23:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 1113.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     72.223.1.23:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 1846.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     72.223.1.23:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 260.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     72.223.1.23:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [63]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7Gv7IyT9cPA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}